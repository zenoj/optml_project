{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T15:54:21.335448Z",
     "start_time": "2024-07-23T15:54:18.795756Z"
    }
   },
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from compression_ops import *\n",
    "from model.simpleMLP import *\n",
    "from optimizers.Beer import BEER\n",
    "from optimizers.Motef import MoTEF\n",
    "from world import create_adjacency_matrix\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import time\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:55:32.479846Z",
     "start_time": "2024-07-23T15:55:32.476929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    backend = 'gloo'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=world_size)\n",
    "\n"
   ],
   "id": "246bb906818868be",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:55:46.190220Z",
     "start_time": "2024-07-23T15:55:46.187415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ],
   "id": "2aa7947f46561ac5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:56:32.480768Z",
     "start_time": "2024-07-23T15:56:32.472792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def motef_worker(rank, world_size, model, train_loader, val_loader, epochs, gamma, eta, lambda_, comp_func, com_ratio,\n",
    "                 adjacency_matrix):\n",
    "    setup(rank, world_size)\n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # initialize optimizer\n",
    "    optim = BEER(world_size, rank, model, train_loader, adjacency_matrix, gamma, eta, lambda_, comp_func, com_ratio)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # go one iteration of the optimizer and return current loss\n",
    "            loss = optim.step(data, target)\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Rank {rank}, Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.6f}\")\n",
    "                print(f\"x norm: {optim.x.norm().item()}, v norm: {optim.v.norm().item()}\")\n",
    "                print(f\"h norm: {optim.h.norm().item()}, g norm: {optim.g.norm().item()}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(\n",
    "            f\"Rank {rank}, Epoch {epoch + 1}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "43521f18cff1b7a1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def worker_fn(rank, world_size, model, trainset, valset, epochs, gamma, eta, lambda_, comp_func, com_ratio,\n",
    "              adjacency_matrix):\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank,\n",
    "                                                                    shuffle=True)\n",
    "    train_loader = DataLoader(trainset, batch_size=128, num_workers=2, sampler=train_sampler)\n",
    "    val_loader = DataLoader(valset, batch_size=128, shuffle=False)\n",
    "    print(f\"rank:{rank}\")\n",
    "    motef_worker(rank, world_size, model, train_loader, val_loader, epochs, gamma, eta, lambda_, comp_func, com_ratio,\n",
    "                 adjacency_matrix)\n",
    "\n"
   ],
   "id": "939a3e7f73083023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T15:56:35.117550Z",
     "start_time": "2024-07-23T15:56:35.113427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_motef(world_size, epochs, gamma, eta, lambda_, comp_func, com_ratio, topology, prob=0.1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    val_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    model = MLP()\n",
    "    model.share_memory()\n",
    "\n",
    "    adjacency_matrix = create_adjacency_matrix(topology, world_size, prob)\n",
    "\n",
    "    mp.spawn(worker_fn, args=(\n",
    "        world_size, model, train_set, val_set, epochs, gamma, eta, lambda_, comp_func, com_ratio, adjacency_matrix),\n",
    "             nprocs=world_size)\n"
   ],
   "id": "ef7f2080aae83ff7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:00:54.394559Z",
     "start_time": "2024-07-23T16:00:52.499881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # for beer: eta=0.01, gamma=0.002, com_ratio=0.2, comp_func=top_k, topology=grid,\n",
    "    # for motef: eta=0.03, gamma=0.001, com_ratio=0.2, comp_func=top_k, topology=grid\n",
    "\n",
    "    world_size = 4\n",
    "    start_time = time.time()\n",
    "    ep = 10\n",
    "    coms = [0.2, 0.8]\n",
    "    gammas = [0.002]\n",
    "    etas = [0.01]\n",
    "    lbds = [0.9, 0.9, 0.1, 0.01]\n",
    "    topologies = ['grid', \"ring\", 'fully-connected', 'star', 'erdos-renyi']\n",
    "    prob = 0.1  # Only used for erdos-renyi topology\n",
    "    comp_func = top_k\n",
    "    optimizer = [MoTEF, BEER]\n",
    "    # for beer: eta=0.01, gamma=0.002, com_ratio=0.2, comp_func=top_k, topology=grid,\n",
    "    # for motef: eta=0.03, gamma=0.001, com_ratio=0.2, comp_func=top_k, topology=grid\n",
    "    for gam, et, lbd, com, topology in itertools.product(gammas, etas, lbds, coms, topologies):\n",
    "        if topology == 'erdos-renyi':\n",
    "            print(f\"gamma={gam}, eta={et}, lambda_={lbd}, com_ratio={com}, topology={topology}, prob={prob}\")\n",
    "        else:\n",
    "            print(f\"gamma={gam}, eta={et}, lambda_={lbd}, com_ratio={com}, topology={topology}\")\n",
    "\n",
    "        run_motef(world_size=world_size, epochs=ep, gamma=gam, eta=et, lambda_=lbd, comp_func=comp_func, com_ratio=com,\n",
    "                  topology=topology, prob=prob)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Total execution time: {total_time:.2f}s\")"
   ],
   "id": "626af24ce1ef75e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma=0.002, eta=0.01, lambda_=0.9, com_ratio=0.2, topology=grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "W0723 18:00:54.336000 138189368956736 torch/multiprocessing/spawn.py:145] Terminating process 32266 via signal SIGTERM\n",
      "W0723 18:00:54.337000 138189368956736 torch/multiprocessing/spawn.py:145] Terminating process 32267 via signal SIGTERM\n",
      "W0723 18:00:54.338000 138189368956736 torch/multiprocessing/spawn.py:145] Terminating process 32268 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mProcessExitedException\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgamma=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgam\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, eta=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00met\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, lambda_=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlbd\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, com_ratio=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcom\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, topology=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtopology\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 24\u001B[0m \u001B[43mrun_motef\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworld_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43met\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlbd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomp_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomp_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcom_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcom\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m          \u001B[49m\u001B[43mtopology\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopology\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprob\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprob\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m total_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal execution time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[8], line 15\u001B[0m, in \u001B[0;36mrun_motef\u001B[0;34m(world_size, epochs, gamma, eta, lambda_, comp_func, com_ratio, topology, prob)\u001B[0m\n\u001B[1;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mshare_memory()\n\u001B[1;32m     13\u001B[0m adjacency_matrix \u001B[38;5;241m=\u001B[39m create_adjacency_matrix(topology, world_size, prob)\n\u001B[0;32m---> 15\u001B[0m \u001B[43mmp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspawn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworker_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomp_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcom_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjacency_matrix\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m         \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:281\u001B[0m, in \u001B[0;36mspawn\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    275\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis method only supports start_method=spawn (got: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    277\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo use a different start_method use:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m torch.multiprocessing.start_processes(...)\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m start_method\n\u001B[1;32m    279\u001B[0m     )\n\u001B[1;32m    280\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg)\n\u001B[0;32m--> 281\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstart_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdaemon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspawn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:237\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m context\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 237\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:177\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProcessExitedException(\n\u001B[1;32m    170\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m terminated with signal \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (error_index, name),\n\u001B[1;32m    171\u001B[0m             error_index\u001B[38;5;241m=\u001B[39merror_index,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    174\u001B[0m             signal_name\u001B[38;5;241m=\u001B[39mname,\n\u001B[1;32m    175\u001B[0m         )\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 177\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProcessExitedException(\n\u001B[1;32m    178\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m terminated with exit code \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (error_index, exitcode),\n\u001B[1;32m    179\u001B[0m             error_index\u001B[38;5;241m=\u001B[39merror_index,\n\u001B[1;32m    180\u001B[0m             error_pid\u001B[38;5;241m=\u001B[39mfailed_process\u001B[38;5;241m.\u001B[39mpid,\n\u001B[1;32m    181\u001B[0m             exit_code\u001B[38;5;241m=\u001B[39mexitcode,\n\u001B[1;32m    182\u001B[0m         )\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_files[error_index], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fh:\n\u001B[1;32m    185\u001B[0m     original_trace \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(fh)\n",
      "\u001B[0;31mProcessExitedException\u001B[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:08:45.072147Z",
     "start_time": "2024-07-23T16:08:43.607977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "implementation of the MoTEF federated learning algorithm (https://arxiv.org/pdf/2405.20114)\n",
    "compare with document MoTEF_Alg.pdf\n",
    "part of the course work for optmization in machine learning\n",
    "\"\"\"\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from compression_ops import *\n",
    "# from model.resnet18 import *\n",
    "from model.simpleMLP import *\n",
    "from optimizers.Beer import BEER\n",
    "from optimizers.Motef import MoTEF\n",
    "from world import create_adjacency_matrix\n",
    "\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    backend = 'gloo'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=world_size)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "def motef_worker(rank, world_size, model, train_loader, val_loader, epochs, gamma, eta, lambda_, comp_func, com_ratio,\n",
    "                 adjacency_matrix):\n",
    "    setup(rank, world_size)\n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # initialize optimizer\n",
    "    optim = BEER(world_size, rank, model, train_loader, adjacency_matrix, gamma, eta, lambda_, comp_func, com_ratio)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # go one iteration of the optimizer and return current loss\n",
    "            loss = optim.step(data, target)\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Rank {rank}, Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.6f}\")\n",
    "                print(f\"x norm: {optim.x.norm().item()}, v norm: {optim.v.norm().item()}\")\n",
    "                print(f\"h norm: {optim.h.norm().item()}, g norm: {optim.g.norm().item()}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(\n",
    "            f\"Rank {rank}, Epoch {epoch + 1}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "def worker_fn(rank, world_size, model, trainset, valset, epochs, gamma, eta, lambda_, comp_func, com_ratio,\n",
    "              adjacency_matrix):\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank,\n",
    "                                                                    shuffle=True)\n",
    "    train_loader = DataLoader(trainset, batch_size=128, num_workers=2, sampler=train_sampler)\n",
    "    val_loader = DataLoader(valset, batch_size=128, shuffle=False)\n",
    "    print(f\"rank:{rank}\")\n",
    "    motef_worker(rank, world_size, model, train_loader, val_loader, epochs, gamma, eta, lambda_, comp_func, com_ratio,\n",
    "                 adjacency_matrix)\n",
    "\n",
    "\n",
    "def run_motef(world_size, epochs, gamma, eta, lambda_, comp_func, com_ratio, topology, prob=0.1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    val_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    model = MLP()\n",
    "    model.share_memory()\n",
    "\n",
    "    adjacency_matrix = create_adjacency_matrix(topology, world_size, prob)\n",
    "\n",
    "    mp.spawn(worker_fn, args=(\n",
    "        world_size, model, train_set, val_set, epochs, gamma, eta, lambda_, comp_func, com_ratio, adjacency_matrix),\n",
    "             nprocs=world_size)\n",
    "\n",
    "\n",
    "def main():\n",
    "    world_size = 4\n",
    "    start_time = time.time()\n",
    "    ep = 10\n",
    "    coms = [0.2, 0.8]\n",
    "    gammas = [0.002]\n",
    "    etas = [0.01]\n",
    "    lbds = [0.9, 0.9, 0.1, 0.01]\n",
    "    topologies = ['grid', \"ring\", 'fully-connected', 'star', 'erdos-renyi']\n",
    "    prob = 0.1  # Only used for erdos-renyi topology\n",
    "    comp_func = top_k\n",
    "    optimizer = [MoTEF, BEER]\n",
    "    # for beer: eta=0.01, gamma=0.002, com_ratio=0.2, comp_func=top_k, topology=grid,\n",
    "    # for motef: eta=0.03, gamma=0.001, com_ratio=0.2, comp_func=top_k, topology=grid\n",
    "    for gam, et, lbd, com, topology in itertools.product(gammas, etas, lbds, coms, topologies):\n",
    "        if topology == 'erdos-renyi':\n",
    "            print(f\"gamma={gam}, eta={et}, lambda_={lbd}, com_ratio={com}, topology={topology}, prob={prob}\")\n",
    "        else:\n",
    "            print(f\"gamma={gam}, eta={et}, lambda_={lbd}, com_ratio={com}, topology={topology}\")\n",
    "\n",
    "        run_motef(world_size=world_size, epochs=ep, gamma=gam, eta=et, lambda_=lbd, comp_func=comp_func, com_ratio=com,\n",
    "                  topology=topology, prob=prob)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Total execution time: {total_time:.2f}s\")\n",
    "        \n",
    "main()\n"
   ],
   "id": "da2ab12665d01430",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma=0.002, eta=0.01, lambda_=0.9, com_ratio=0.2, topology=grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jay/anaconda3/envs/pytorch/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker_fn' on <module '__main__' (built-in)>\n",
      "W0723 18:08:45.000000 138189368956736 torch/multiprocessing/spawn.py:145] Terminating process 32639 via signal SIGTERM\n",
      "W0723 18:08:45.001000 138189368956736 torch/multiprocessing/spawn.py:145] Terminating process 32641 via signal SIGTERM\n",
      "W0723 18:08:45.002000 138189368956736 torch/multiprocessing/spawn.py:145] Terminating process 32642 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mProcessExitedException\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 136\u001B[0m\n\u001B[1;32m    133\u001B[0m         total_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m    134\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal execution time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 136\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[12], line 130\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgamma=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgam\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, eta=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00met\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, lambda_=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlbd\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, com_ratio=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcom\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, topology=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtopology\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 130\u001B[0m \u001B[43mrun_motef\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworld_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43met\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlbd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomp_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomp_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcom_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcom\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m          \u001B[49m\u001B[43mtopology\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopology\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprob\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprob\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m total_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal execution time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[12], line 105\u001B[0m, in \u001B[0;36mrun_motef\u001B[0;34m(world_size, epochs, gamma, eta, lambda_, comp_func, com_ratio, topology, prob)\u001B[0m\n\u001B[1;32m    101\u001B[0m model\u001B[38;5;241m.\u001B[39mshare_memory()\n\u001B[1;32m    103\u001B[0m adjacency_matrix \u001B[38;5;241m=\u001B[39m create_adjacency_matrix(topology, world_size, prob)\n\u001B[0;32m--> 105\u001B[0m \u001B[43mmp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspawn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworker_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomp_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcom_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjacency_matrix\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m         \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:281\u001B[0m, in \u001B[0;36mspawn\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    275\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis method only supports start_method=spawn (got: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    277\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo use a different start_method use:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m torch.multiprocessing.start_processes(...)\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m start_method\n\u001B[1;32m    279\u001B[0m     )\n\u001B[1;32m    280\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg)\n\u001B[0;32m--> 281\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstart_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdaemon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspawn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:237\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m context\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 237\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:177\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProcessExitedException(\n\u001B[1;32m    170\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m terminated with signal \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (error_index, name),\n\u001B[1;32m    171\u001B[0m             error_index\u001B[38;5;241m=\u001B[39merror_index,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    174\u001B[0m             signal_name\u001B[38;5;241m=\u001B[39mname,\n\u001B[1;32m    175\u001B[0m         )\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 177\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProcessExitedException(\n\u001B[1;32m    178\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m terminated with exit code \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (error_index, exitcode),\n\u001B[1;32m    179\u001B[0m             error_index\u001B[38;5;241m=\u001B[39merror_index,\n\u001B[1;32m    180\u001B[0m             error_pid\u001B[38;5;241m=\u001B[39mfailed_process\u001B[38;5;241m.\u001B[39mpid,\n\u001B[1;32m    181\u001B[0m             exit_code\u001B[38;5;241m=\u001B[39mexitcode,\n\u001B[1;32m    182\u001B[0m         )\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_files[error_index], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fh:\n\u001B[1;32m    185\u001B[0m     original_trace \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(fh)\n",
      "\u001B[0;31mProcessExitedException\u001B[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
